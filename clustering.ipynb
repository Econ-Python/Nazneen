{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120a0095",
   "metadata": {},
   "outputs": [],
   "source": [
    "## correlation visualization improvement\n",
    "cols = [list of columns]\n",
    "corr = df[cols].corr()\n",
    "corr.style.background_gradient(axis=None) # this line adds gradient based on values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fd88067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from teaching_tools.widgets import ClusterWidget, SCFClusterWidget\n",
    "from scipy.stats.mstats import trimmed_var\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aac073be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install teaching-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea656914",
   "metadata": {},
   "source": [
    "### data download from here https://sda.berkeley.edu/sdaweb/docs/scfcomb2019/DOC/hcbkh01.htm\n",
    "and then you can fetch it using read_csv and use the library\n",
    "\n",
    "scfc = SCFClusterWidget(x=df[\"DEBT\"], y=df[\"HOUSES\"], n_clusters=3)\n",
    "scfc.show()\n",
    "\n",
    "for understanding how clustering works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52553ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = KMeans(n_clusters=3, random_state =42)\n",
    "print(\"model type:\", type(model))\n",
    "\n",
    "# Fit model to data\n",
    "model.fit(X)\n",
    "\n",
    "# Assert that model has been fit to data\n",
    "check_is_fitted(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8cfdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = model.labels_\n",
    "print(\"labels type:\", type(labels))\n",
    "print(\"labels shape:\", labels.shape)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e35db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    x = df['1st column'] ,\n",
    "    y = df['second column'],\n",
    "    hue = labels,\n",
    "    palette = 'deep'\n",
    ")\n",
    "plt.xlabel()\n",
    "plt.ylabel()\n",
    "plt.title();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac8c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = model.cluster_centers_\n",
    "print(\"centroids type:\", type(centroids))\n",
    "print(\"centroids shape:\", centroids.shape)\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2410d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding centroid to the plot\n",
    "# Plot \"HOUSES\" vs \"DEBT\", add centroids\n",
    "sns.scatterplot(\n",
    "    x = df['1st column'],\n",
    "    y = df['2nd column'],\n",
    "    hue = labels,\n",
    "    palette = 'deep'\n",
    ")\n",
    "plt.scatter(\n",
    "    x = centroids[:, 0] / 1e6,\n",
    "    y = centroids[:, 1] / 1e6,\n",
    "    color = 'gray',\n",
    "    marker = \"*\",\n",
    "    s = 150\n",
    "    \n",
    ")\n",
    "plt.xlabel()\n",
    "plt.ylabel()\n",
    "plt.title();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cb0445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the euclidean distance between data points and  centroid, to get the sum of L2 norm distance of all the points\n",
    "inertia = model.inertia_\n",
    "print(\"inertia type:\", type(inertia))\n",
    "print(\"Inertia (3 clusters):\", inertia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8434790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# silhouette score is a measure between [-1,1], between a cluster data points and non cluster data points fron a centroid\n",
    "# i.e. b-a / max(a,b)\n",
    "ss = silhouette_score(X, labels)\n",
    "print(\"ss type:\", type(ss))\n",
    "print(\"Silhouette Score (3 clusters):\", ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e9ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## finding optimal number of clusters\n",
    "n_clusters = range(2,13)\n",
    "inertia_errors = []\n",
    "silhouette_scores = []\n",
    "\n",
    "# Add `for` loop to train model and calculate inertia, silhouette score.\n",
    "for k in n_clusters:\n",
    "    # build the model for k clusters\n",
    "    model = KMeans(n_clusters = k, random_state =42)\n",
    "    # train model\n",
    "    model.fit(X)\n",
    "    # calculate inertia\n",
    "    inertia_errors.append(model.inertia_)\n",
    "    #calculate silhuoette score\n",
    "    silhouette_scores.append(silhouette_score(X, model.labels_))\n",
    "\n",
    "print(\"inertia_errors type:\", type(inertia_errors))\n",
    "print(\"inertia_errors len:\", len(inertia_errors))\n",
    "print(\"Inertia:\", inertia_errors)\n",
    "print()\n",
    "print(\"silhouette_scores type:\", type(silhouette_scores))\n",
    "print(\"silhouette_scores len:\", len(silhouette_scores))\n",
    "print(\"Silhouette Scores:\", silhouette_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d325c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot `inertia_errors` by `n_clusters`\n",
    "plt.plot(n_clusters, inertia_errors)\n",
    "plt.xlabel(\"no. of Clusters (k)\")\n",
    "plt.ylabel(\"Inertia (L2 norm)\")\n",
    "plt.title(\"K-Means Model: Inertia vs Number of Clusters\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbf0df9",
   "metadata": {},
   "source": [
    "For intertia, best value is where you see this bent enbow, so the one where value starts flattening, min is better here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beb2f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot `silhouette_scores` vs `n_clusters`\n",
    "plt.plot(n_clusters, silhouette_scores)\n",
    "plt.xlabel(\"no. of Clusters (k)\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.title(\"K-Means Model: Silhouette Score vs Number of Clusters\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc95f2ac",
   "metadata": {},
   "source": [
    "For silhouette score, higher score is better, so the one where drastic drop happens. comnbining both these plots and eye balling you canj find best value for clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ec26a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the mean value of these clusers\n",
    "cluster_means = X.groupby(model.labels_).mean()\n",
    "\n",
    "print(\"cluster_means type:\", type(xgb))\n",
    "print(\"cluster_means shape:\", xgb.shape)\n",
    "\n",
    "# this is same as the one we get from cluster centers\n",
    "model.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9d1cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting set of feature based which ones have largest variance\n",
    "top_var = df.apply(trimmed_var, limits = (0.1,0.1)).sort_values().tail(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
